{% extends "base.html" %}
{% block content %}
  <section class="section container">
    <div class="section-header">
      <h1>{{ challenge.name }} Challenge {% if challenge.locked %}[Closed]{% endif %}</h1>
    </div>

    <div class="section-content">
      <h2>Task</h2>
      <p>The goal for ISIC 2019 is classify dermoscopic images among nine different diagnostic
        categories:</p>
      <ol>
        <li>Melanoma</li>
        <li>Melanocytic nevus</li>
        <li>Basal cell carcinoma</li>
        <li>Actinic keratosis</li>
        <li>Benign keratosis (solar lentigo / seborrheic keratosis / lichen planus-like keratosis)
        </li>
        <li>Dermatofibroma</li>
        <li>Vascular lesion</li>
        <li>Squamous cell carcinoma</li>
        <li>None of the others</li>
      </ol>
      <p>25,331 images are available for training across 8 different categories. Additionally, the
        test<br>
        dataset (planned release August 2nd) will contain an additional outlier class not
        represented in<br>
        the training data, which developed systems must be able to identify.</p>
      <p>Two tasks will be available for participation: 1) classify dermoscopic images without
        meta-data,<br>
        and 2) classify images with additional available meta-data. Task 1’s deadline will be August
        16th.<br>
        Task 2 will be August 23th, after release of test meta-data on August 16th. Participants of
        Task 2<br>
        must submit to Task 1 as well, though participants can submit to Task 1 alone.</p>
      <p>In addition to submitting predictions, each competitor is required to submit a link to a
        manuscript<br>
        describing the methods used to generate predictions.</p>
      <h2 class="code-line" data-line-start=34 data-line-end=35><a id="Submission_34"></a>Submission
      </h2>
      <p>Submissions are made to the<br>
        <a href="https://challenge.isic-archive.com/">ISIC Challenge submission system</a>, which
        provides automated<br>
        format validation, pre-scoring, metadata editing capabilties.</p>
      <h2 class="code-line" data-line-start=41 data-line-end=42><a id="Evaluation_41"></a>Evaluation
      </h2>

      <h4>Goal Metric</h4>
      <p><em>Submissions are scored using a normalized multi-class accuracy metric</em> (balanced across categories).
      Tied positions will be broken using the area under the receiver operating characteristic curve
      (AUC) metric.</p>

      <h5>Definition</h5>
      <p>Normalized (or balanced) multi-class accuracy is defined as the accuracies of each category,
      weighted by the category prevalence. Specifically, it is the arithmetic mean of the
      <code>(&lt;category&gt;_true_positives / &lt;category&gt;_positives)</code> across each of the diagnostic categories. This
      metric is semantically equivalent to the average recall score.</p>

      <h5>Rationale</h5>
      <p>Clinical application on skin lesion classification has two goals eventually: Giving specific
      information and treatment options for a lesion, and detecting skin cancer with a reasonable
      sensitivity and specificity. The first task needs a correct specific diagnosis out of multiple
      classes, whereas the second demands a binary decision "biopsy" versus "don’t biopsy". In the
      former ISIC Challenges, focus was on the second task, therefore this year we want to rank for the
      more ambitious metric of normalized multiclass accuracy, as it is also closer to real evaluation of
      a dermatologist. This is also important for the extending reader study, where the winning
      algorithm(s) will be compared to physicians performance in classification of digital images.</p>

      <h4>Other Metrics</h4>
      <p>Participants will be ranked and awards granted based only on the balanced multi-class accuracy metric.
      However, for scientific completeness, predicted responses will also have the following metrics
      computed (comparing prediction vs. ground truth) for each image:</p>
      <h5>Category Metrics</h5>
      <ul>
        <li><a href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity#Sensitivity">sensitivity<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li>
        <li><a href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity#Specificity">specificity<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li>
        <li><a href="https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification">accuracy<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li>
        <li><a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve">area under the receiver operating characteristic curve (AUC)<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li>
        <li><a href="http://fastml.com/what-you-wanted-to-know-about-mean-average-precision/">mean average precision<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li>
        <li><a href="https://en.wikipedia.org/wiki/F1_score">F1 score<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li> <li>[AUC integrated between 80% to 100% sensitivity (AUC80)]</li>
        <li><a href="https://en.wikipedia.org/wiki/Positive_and_negative_predictive_values">positive predictive value (PPV)<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li>
        <li><a href="https://en.wikipedia.org/wiki/Positive_and_negative_predictive_values">negative predictive value (NPV)<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li>
      </ul>
      <h5>Aggregate Metrics</h5>
      <ul>
        <li>average AUC across all diagnoses</li> <li>malignant vs. benign diagnoses category AUC</li>
      </ul>

      <h4>Validation Scoring</h4>
      <p>All submissions to the ISIC Challenge are immediately issued a validation score. <em>This validation
      score is not intended to be used for algorithm ranking or evaluation</em>, but is provided for a sanity
      check of submission data (e.g. to guard against instances where prediction labels are mismatched).</p>

      <p>The validation score is computed with the goal metric (balanced multi-class accuracy), taken against
      a small (~100), non-representative, pre-determined subset of images.</p>

      <p>For reference, a random submission generates a validation score of about 0.3.</p>

      <h4>Final Score Release</h4>
      <p>Final scores and a public leaderboard are released shortly after the conclusion of the ISIC
      Challenge submission period.</p>

      <h4>Transparency Statement</h4>
      <p>The code of
      <a href="https://github.com/ImageMarkup/isic-challenge-scoring/">the <code>isic-challenge-scoring</code> package<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>
      is used for actual score computation. This code is open source, permissively licensed, and published,
      to facilitate external auditing.</p>

    <h2 class="code-line" data-line-start=48 data-line-end=49><a id="Awards_48"></a>Awards</h2>
      <p>Cash prizes of $4,000, $2,000, and $1,000 will be awarded to the first, second, and third
        place<br>
        participants of image-only and meta-data tasks. USD will be awarded to winners of each of
        the<br>
        tasks. The monetary prizes for the winners of the challenge will be awarded after the MICCAI<br>
        Workshop in Shenzhen, China, in October 2019. The prizes are being provided by Canfield
        Scientific,<br>
        Inc., a US company, and are subject to any restrictions incumbent on the sponsor. Winners
        will be<br>
        asked to identify a recipient individual or entity who will be required to provide tax
        documentation<br>
        (U.S. citizens- IRS form W-9, non-U.S. citizens Form W-8 BEN).</p>

      <strong>The results are presented at the <a href="https://workshop2019.isic-archive.com">ISIC Skin Image Analysis Workshop @ CVPR 2019</a></strong>.

      <h2 class="code-line" data-line-start=57 data-line-end=58><a id="Sponsors_57"></a>Sponsors
      </h2>
      <div class="columns">
        <div class="column">
          <ul>
            <li><strong>Canfield Scientific</strong></li>
            <li><strong>IBM</strong></li>
            <li><strong>MetaOptima</strong></li>
          </ul>
          <h4 class="code-line" data-line-start=62 data-line-end=63><a id="Clinical_Chairs_62"></a>Clinical
            Chairs</h4>
          <ul>
            <li><strong>Josep Malvehy, M.D.</strong> ;<br>
              <em>University Hospital Clinic of Barcelona, Barcelona, Spain</em></li>
            <li><strong>Allan Halpern, M.D.</strong> ;<br>
              <em>Memorial Sloan Kettering Cancer Center, New York City, NY, USA</em></li>
          </ul>
          <h4 class="code-line" data-line-start=68 data-line-end=69><a
              id="Computer_Vision_Chairs_68"></a>Computer Vision Chairs</h4>
          <ul>
            <li><strong>Noel C. F. Codella, Ph.D.</strong> ;<br>
              <em>IBM Research, Yorktown Heights, NY, USA</em></li>
          </ul>
        </div>

        <div class="column">
          <h4 class="code-line" data-line-start=72 data-line-end=73><a
              id="Challenge_CoChairs_72"></a>Challenge Co-Chairs</h4>
          <ul>
            <li><strong>M. Emre Celebi, Ph.D.</strong> ;<br>
              <em>University of Central Arkansas, Conway, AR, USA</em></li>
            <li><strong>Marc Combalia, M.S.</strong> ;<br>
              <em>Fundació Clínic per a la Recerca Biomèdica, Barcelona, Spain</em></li>
            <li><strong>David Gutman, M.D., Ph.D.</strong> ;<br>
              <em>Emory University, Atlanta, GA, USA</em></li>
            <li><strong>Brian Helba</strong> ;<br>
              <em>Kitware, Inc., Clifton Park, NY, USA</em></li>
            <li><strong>Harald Kittler, M.D.</strong> ;<br>
              <em>Medical University of Vienna, Vienna, Austria</em></li>
            <li><strong>Veronica Rotemberg, M.D., Ph.D.</strong> ;<br>
              <em>Memorial Sloan Kettering Cancer Center, New York City, NY, USA</em></li>
            <li><strong>Philipp Tschandl, M.D., Ph.D.</strong> ;<br>
              <em>Medical University of Vienna, Vienna, Austria</em></li>
          </ul>
        </div>
      </div>
      Note: Any organizations/companies affiliated with members of the organizing committee are not
      excluded from participation in the Challenge, but must assure that their submissions are
      completely independent of the members of the organizing committee.

      {% include 'partials/task-listing.html' %}
    </div>
  </section>
{% endblock %}
